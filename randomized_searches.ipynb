{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.style.use('seaborn-notebook')\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import src.scrubbing_develop as scrubbing\n",
    "import src.utility \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['p7_9','p10_12', 'p13_18', 'p19_24', 'p25_36', '94013', '94014', '94080', '94101', '94102', '94103', '94104',\n",
    "       '94105', '94107', '94108', '94109', '94110', '94111', '94112', '94114',\n",
    "       '94115', '94116', '94117', '94118', '94120', '94121', '94122', '94123',\n",
    "       '94124', '94127', '94129', '94130', '94131', '94132', '94133', '94134',\n",
    "       '94143', '94158']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle('data/sf_inspection_master.pkl')\n",
    "df8 = scrubbing.remove_rows_zero_violation2(df2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df8['y_label']\n",
    "X = df8[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.20, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_tr, y_tr, test_size=0.25, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False),\n",
      "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
      "          param_distributions={'learning_rate': [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.085, 0.09, 0.095], 'max_depth': range(1, 10), 'max_features': range(2, 10), 'n_estimators': range(10, 120, 2), 'subsample': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "0.6979911474293496\n",
      "0.035 6 7 34 0.8\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# load the diabetes datasets\n",
    "#dataset = datasets.load_diabetes()\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'learning_rate': [x/200 for x in range(1,20,1)], 'max_depth': range(1,10,1), \n",
    "              'max_features':range(2,10,1), 'n_estimators': range(10,120,2), 'subsample': [x/100 for x in range(10,100,5)]}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = GradientBoostingClassifier()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, n_jobs=-1)\n",
    "rsearch.fit(X_train.values, y_train.values)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.learning_rate, rsearch.best_estimator_.max_depth, \n",
    "      rsearch.best_estimator_.max_features, rsearch.best_estimator_.n_estimators,\n",
    "      rsearch.best_estimator_.subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.773\n",
      "Accuracy score (validation): 0.731\n",
      "Accuracy score (test): 0.706\n"
     ]
    }
   ],
   "source": [
    "# Let's use learning rate of 0.5\n",
    "gb = GradientBoostingClassifier(n_estimators=40, learning_rate = 0.08, max_features=4, max_depth = 8, subsample=0.4, random_state = 0)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_validation, y_validation)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "# The \"validation\" here is a correct term. It is not a \"test\" set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(gb, X_tr, y_tr, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70573248, 0.72413793, 0.70114943, 0.68710089, 0.69604087])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7028323205700759"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "          fit_params=None, iid=True, n_iter=8000, n_jobs=-1,\n",
      "          param_distributions={'max_depth': range(5, 50), 'min_samples_split': range(2, 60), 'max_features': range(2, 30), 'min_samples_leaf': range(2, 40)},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "0.6979911474293496\n",
      "15 54 27 10\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {'max_depth': range(5,50,1), 'min_samples_split': range(2,60,1), \n",
    "              'max_features': range(2,30,1), 'min_samples_leaf': range(2,40,1)}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = DecisionTreeClassifier()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=8000, n_jobs=-1)\n",
    "rsearch.fit(X_train.values, y_train.values)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.max_depth, rsearch.best_estimator_.min_samples_split, \n",
    "      rsearch.best_estimator_.max_features, rsearch.best_estimator_.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.712\n",
      "Accuracy score (validation): 0.693\n",
      "Accuracy score (test): 0.696\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=12, min_samples_split=53, max_features=16, \n",
    "                            min_samples_leaf=7, random_state = 0)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(dt.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(dt.score(X_validation, y_validation)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(dt.score(X_test, y_test)))\n",
    "# The \"validation\" here is a correct term. It is not a \"test\" set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "          fit_params=None, iid=True, n_iter=8000, n_jobs=-1,\n",
      "          param_distributions={'max_depth': range(5, 50), 'min_samples_split': range(2, 60), 'n_estimators': range(2, 40, 2), 'max_features': range(2, 30), 'min_samples_leaf': range(2, 40)},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "0.7007150153217568\n",
      "43 22 24 9 3\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {'max_depth': range(5,50,1), 'min_samples_split': range(2,60,1), 'n_estimators': range(2,40,2),\n",
    "              'max_features': range(2,30,1), 'min_samples_leaf': range(2,40,1)}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = RandomForestClassifier()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=8000, n_jobs=-1)\n",
    "rsearch.fit(X_train.values, y_train.values)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.max_depth, rsearch.best_estimator_.min_samples_split, \n",
    "      rsearch.best_estimator_.n_estimators, rsearch.best_estimator_.max_features, \n",
    "      rsearch.best_estimator_.min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.750\n",
      "Accuracy score (validation): 0.714\n",
      "Accuracy score (test): 0.703\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=11, min_samples_split=4, max_features=16, n_estimators=34,\n",
    "                            min_samples_leaf=4, random_state = 0)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_validation, y_validation)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "# The \"validation\" here is a correct term. It is not a \"test\" set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
      "          fit_params=None, iid=True, n_iter=1000, n_jobs=-1,\n",
      "          param_distributions={'n_estimators': range(10, 60), 'learning_rate': [0.06666666666666667, 0.07333333333333333, 0.08, 0.08666666666666667, 0.09333333333333334, 0.1, 0.10666666666666667, 0.11333333333333333, 0.12, 0.12666666666666668, 0.13333333333333333, 0.14, 0.14666666666666667, 0.1533333333333333...22, 0.22666666666666666, 0.23333333333333334, 0.24, 0.24666666666666667, 0.25333333333333335, 0.26]},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "0.6789240721824992\n",
      "0.18666666666666668 51\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {'n_estimators': range(10,60,1), 'learning_rate': [x/300 for x in range(20,80,2)]}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = AdaBoostClassifier()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=1000, n_jobs=-1)\n",
    "rsearch.fit(X_train.values, y_train.values)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.learning_rate,  rsearch.best_estimator_.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.673\n",
      "Accuracy score (validation): 0.681\n",
      "Accuracy score (test): 0.685\n"
     ]
    }
   ],
   "source": [
    "adc = AdaBoostClassifier(learning_rate=0.17, n_estimators=56, random_state = 0)\n",
    "adc.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(adc.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(adc.score(X_validation, y_validation)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(adc.score(X_test, y_test)))\n",
    "# The \"validation\" here is a correct term. It is not a \"test\" set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
