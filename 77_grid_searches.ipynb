{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.style.use('seaborn-notebook')\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import src.scrubbing as scrubbing\n",
    "import src.utility \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['p7_9','p10_12', 'p13_18', 'p19_24', 'p25_36', '94013', '94014', '94080', '94101', '94102', '94103', '94104',\n",
    "       '94105', '94107', '94108', '94109', '94110', '94111', '94112', '94114',\n",
    "       '94115', '94116', '94117', '94118', '94120', '94121', '94122', '94123',\n",
    "       '94124', '94127', '94129', '94130', '94131', '94132', '94133', '94134',\n",
    "       '94143', '94158']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_pickle('data/sf_inspection_master.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df8['y_label']\n",
    "X = df8[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.20, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_tr, y_tr, test_size=0.25, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False),\n",
      "          fit_params=None, iid=True, n_iter=5000, n_jobs=-1,\n",
      "          param_distributions={'learning_rate': [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08, 0.085, 0.09, 0.095], 'max_depth': range(1, 10), 'max_features': range(2, 10), 'n_estimators': range(10, 120, 2), 'subsample': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "0.7020769492679605\n",
      "0.075 8 4 40 0.4\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# load the diabetes datasets\n",
    "#dataset = datasets.load_diabetes()\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'learning_rate': [x/200 for x in range(1,20,1)], 'max_depth': range(1,10,1), \n",
    "              'max_features':range(2,10,1), 'n_estimators': range(10,120,2), 'subsample': [x/100 for x in range(10,100,5)]}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = GradientBoostingClassifier()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, n_jobs=-1)\n",
    "rsearch.fit(X_train.values, y_train.values)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.learning_rate, rsearch.best_estimator_.max_depth, \n",
    "      rsearch.best_estimator_.max_features, rsearch.best_estimator_.n_estimators,\n",
    "      rsearch.best_estimator_.subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.773\n",
      "Accuracy score (validation): 0.731\n",
      "Accuracy score (test): 0.706\n"
     ]
    }
   ],
   "source": [
    "# Let's use learning rate of 0.5\n",
    "gb = GradientBoostingClassifier(n_estimators=40, learning_rate = 0.08, max_features=4, max_depth = 8, subsample=0.4, random_state = 0)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_validation, y_validation)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "# The \"validation\" here is a correct term. It is not a \"test\" set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(gb, X_tr, y_tr, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70573248, 0.72413793, 0.70114943, 0.68710089, 0.69604087])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7028323205700759"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(dataset.data, dataset.target)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
