{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.style.use('seaborn-notebook')\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import src.scrubbing_develop as scrubbing\n",
    "import src.utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['p7_9','p10_12', 'p13_18', 'p19_24', 'p25_36', '94013', '94014', '94080', '94101', '94102', '94103', '94104',\n",
    "       '94105', '94107', '94108', '94109', '94110', '94111', '94112', '94114',\n",
    "       '94115', '94116', '94117', '94118', '94120', '94121', '94122', '94123',\n",
    "       '94124', '94127', '94129', '94130', '94131', '94132', '94133', '94134',\n",
    "       '94143', '94158']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df2, X, y) = scrubbing.scrub_all(df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle('data/sf_inspection_master.pkl')\n",
    "df3 = scrubbing.remove_rows_zero_violation2(df2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df3['y_label']\n",
    "X = df3[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.25, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_tr, y_tr, test_size=0.25, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40518605, -0.24633135,  0.07590432,  0.18925423,  0.11127685,\n",
       "         0.        ,  0.08676416,  0.        ,  0.        , -0.3891833 ,\n",
       "         0.45053804,  1.14957605, -0.11758996, -0.73413507, -0.06419537,\n",
       "         1.13403706,  1.37134309, -0.20583216, -0.01628042,  0.75256999,\n",
       "        -0.79661287,  0.62498681, -0.0849984 ,  0.00966387, -0.30427112,\n",
       "        -0.07869748,  0.55801264,  1.80633784, -0.39766452,  0.49712313,\n",
       "        -0.29723071, -0.31138788, -0.04337178,  0.537783  ,  0.4749317 ,\n",
       "         0.40737264,  0.        , -0.9495466 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.78708681])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6895424836601307"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.575\n",
      "Accuracy score (validation): 0.614\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.599\n",
      "Accuracy score (validation): 0.623\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.666\n",
      "Accuracy score (validation): 0.675\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.697\n",
      "Accuracy score (validation): 0.698\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.697\n",
      "Accuracy score (validation): 0.693\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.692\n",
      "Accuracy score (validation): 0.690\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.697\n",
      "Accuracy score (validation): 0.693\n"
     ]
    }
   ],
   "source": [
    "# Let's use learning rate of 0.75\n",
    "gb = GradientBoostingClassifier(n_estimators=20, learning_rate = 0.75, max_features=2, max_depth = 2, random_state = 0)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_validation, y_validation)))\n",
    "# The \"validation\" here is a correct term. It is not a \"test\" set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
